---
permalink: /
title: "ğŸ‘‹ About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


Hi! My name is **Aiwei Liu (åˆ˜ç‘·ç®)**. I am a final-year Ph.D. student at the [School of Software](https://www.thss.tsinghua.edu.cn/) in [Tsinghua University](https://www.tsinghua.edu.cn/), where I am advised by Prof. [Lijie Wen](https://www.thss.tsinghua.edu.cn/faculty/wenlijie.htm). Before that, I received my B.Eng. degree from the [Software Institue](https://software.nju.edu.cn/) in [Nanjing University](https://www.nju.edu.cn/) in 2020.

Currently, I'm serving as a Visiting Scholar at the [UIC BDSC Lab](https://bdsc-uic.github.io/people.html), working under the supervision of Prof. [Philip S. Yu](https://cs.uic.edu/profiles/philip-yu/) (ACM Fellow, IEEE Fellow).

Previously, I was a research intern at [Apple's AIML Group](https://machinelearning.apple.com/), where I worked under the supervision of Dr. [Meng Cao](https://openreview.net/profile?id=~Meng_Cao2).

Additionally, I was serving as a Visiting Scholar at [CUHK MISC Lab](https://misc-lab.cse.cuhk.edu.hk/people/), working under the supervision of Prof. [Irwin King](https://www.cse.cuhk.edu.hk/irwin.king/home) (ACM Fellow, IEEE Fellow).



# â­ Research Highlights 

<div class="paper-container">
<div class="paper-image">
<img src="images/probe.png" alt="LLM Watermarking Overview">
</div>
<div class="paper-text">
<div class="paper-title">Can Watermarked LLMs be Identified by Users via Crafted Prompts?</div>
<p class="paper-authors"><strong>Aiwei Liu</strong>, Sheng Guan, Yiming Liu, Leyi Pan, Yifei Zhang, Liancheng Fang, Lijie Wen, Philip S. Yu, Xuming Hu</p>
<p class="paper-venue">Proceedings of ICLR 2025</p>
<p class="paper-links"><a href="https://arxiv.org/pdf/2410.03168">[Paper]</a> <a href="https://github.com/THU-BPM/Watermarked_LLM_Identification">[Code]</a></p>
</div>
</div>

<div class="paper-container">
<div class="paper-image">
<img src="images/tis-dpo.png" alt="LLM Watermarking Overview">
</div>
<div class="paper-text">
<div class="paper-title">TIS-DPO: Token-level Importance Sampling for Direct Preference Optimization With Estimated Weights</div>
<p class="paper-authors"><strong>Aiwei Liu</strong>, Haoping Bai, Zhiyun Lu, Yanchao Sun, Xiang Kong, Simon Wang, Jiulong Shan, Albin Madappally Jose, Xiaojiang Liu, Lijie Wen, Philip S. Yu, Meng Cao</p>
<p class="paper-venue">Proceedings of ICLR 2025</p>
<p class="paper-links"><a href="https://arxiv.org/abs/2410.04350">[Paper]</a> <a href="https://arxiv.org/abs/2410.04350">[Code]</a></p>
</div>
</div>

<div class="paper-container">
<div class="paper-image">
<img src="images/markllm.png" alt="LLM Watermarking Overview">
</div>
<div class="paper-text">
<div class="paper-title">MarkLLM: An Open-Source Toolkit for LLM Watermarking</div>
<p class="paper-authors">Leyi Pan, <strong>Aiwei Liu*</strong>, Zhiwei He, Zitian Gao, Xuandong Zhao, Yijian Lu, Binglin Zhou, Shuliang Liu, Xuming Hu, Lijie Wen, Irwin King, Philip S. Yu</p>
<p class="paper-venue">Proceedings of EMNLP 2024 Demo</p>
<p class="paper-links"><a href="https://arxiv.org/pdf/2405.10051">[Paper]</a> <a href="https://github.com/THU-BPM/MarkLLM">[Code]</a></p>
</div>
</div>

<div class="paper-container">
<div class="paper-image">
<img src="images/survey.png" alt="LLM Watermarking Overview">
</div>
<div class="paper-text">
<div class="paper-title">A Survey of Text Watermarking in the Era of Large Language Models</div>
<p class="paper-authors"><strong>Aiwei Liu</strong>, Leyi Pan, Yijian Lu, Jingjing Li, Xuming Hu, Xi Zhang, Lijie Wen, Irwin King, Hui Xiong, Philip S. Yu</p>
<p class="paper-venue">ACM Computing Surveys</p>
<p class="paper-links"><a href="https://arxiv.org/pdf/2312.07913.pdf">[Paper]</a> <a href="https://survey-text-watermark.github.io/">[Home]</a></p>
</div>
</div>

<div class="paper-container">
<div class="paper-image">
<img src="images/dlma.png" alt="LLM Watermarking Overview">
</div>
<div class="paper-text">
<div class="paper-title">Direct Large Language Model Alignment Through Self-Rewarding Contrastive Prompt Distillation</div>
<p class="paper-authors"><strong>Aiwei Liu</strong>, Haoping Bai, Zhiyun Lu, Xiang Kong, Simon Wang, Jiulong Shan, Meng Cao, Lijie Wen</p>
<p class="paper-venue">Proceedings of ACL 2024</p>
<p class="paper-links"><a href="https://arxiv.org/pdf/2402.11907.pdf">[Paper]</a> <a href="https://github.com/THU-BPM/Direct_LLM_Alignment">[Code]</a></p>
</div>
</div>

<div class="paper-container">
<div class="paper-image">
<img src="images/SIR.png" alt="LLM Watermarking Overview">
</div>
<div class="paper-text">
<div class="paper-title">A Semantic Invariant Robust Watermark for Large Language Models</div>
<p class="paper-authors"><strong>Aiwei Liu</strong>, Leyi Pan, Xuming Hu, Shiao Meng, Lijie Wen</p>
<p class="paper-venue">Proceedings of ICLR 2024</p>
<p class="paper-links"><a href="https://arxiv.org/pdf/2310.06356.pdf">[Paper]</a> <a href="https://github.com/THU-BPM/Robust_Watermark">[Code]</a></p>
</div>
</div>

<div class="paper-container">
<div class="paper-image">
<img src="images/UPV.png" alt="LLM Watermarking Overview">
</div>
<div class="paper-text">
<div class="paper-title">An Unforgeable Publicly Verifiable Watermark for Large Language Models</div>
<p class="paper-authors"><strong>Aiwei Liu</strong>, Leyi Pan, Xuming Hu, Shuang Li, Lijie Wen, Irwin King, Philip S. Yu</p>
<p class="paper-venue">Proceedings of ICLR 2024</p>
<p class="paper-links"><a href="https://arxiv.org/pdf/2307.16230.pdf">[Paper]</a> <a href="https://github.com/THU-BPM/unforgeable_watermark">[Code]</a></p>
</div>
</div>

<div class="paper-container">
<div class="paper-image">
<img src="images/cg-sql.png" alt="LLM Watermarking Overview">
</div>
<div class="paper-text">
<div class="paper-title">Exploring the Compositional Generalization in Context Dependent Text-to-SQL Parsing </div>
<p class="paper-authors"><strong>Aiwei Liu</strong>, Wei Liu, Xuming Hu, Shuang Li, Fukun Ma, Yawen Yang, Lijie Wen</p>
<p class="paper-venue">Findings of ACL 2023</p>
<p class="paper-links"><a href="https://aclanthology.org/2023.findings-acl.43.pdf">[Paper]</a> <a href="https://github.com/THU-BPM/CD-Text2SQL-CG">[Code]</a></p>
</div>
</div>



<div class="paper-container">
<div class="paper-image">
<img src="images/cwba.png" alt="LLM Watermarking Overview">
</div>
<div class="paper-text">
<div class="paper-title">Character-level White-Box Adversarial Attacks against Transformers via Attachable Subwords Substitution</div>
<p class="paper-authors"><strong>Aiwei Liu</strong>, Honghai Yu, Xuming Hu, Shu'ang Li, Li Lin, Fukun Ma, Yawen Yang, Lijie Wen</p>
<p class="paper-venue">Proceedings of EMNLP 2022</p>
<p class="paper-links"><a href="https://arxiv.org/abs/2210.17004">[Paper]</a> <a href="https://github.com/THU-BPM/CWBA">[Code]</a></p>
</div>
</div>

<div class="paper-container">
<div class="paper-image">
<img src="images/sql.png" alt="LLM Watermarking Overview">
</div>
<div class="paper-text">
<div class="paper-title">Semantic Enhanced Text-to-SQL Parsing via Iteratively Learning Schema Linking Graph</div>
<p class="paper-authors"><strong>Aiwei Liu</strong>, Xuming Hu, Li Lin, Lijie Wen</p>
<p class="paper-venue">Proceedings of SIGKDD 2022</p>
<p class="paper-links"><a href="https://arxiv.org/pdf/2207.08814">[Paper]</a> <a href="https://github.com/THU-BPM/ISESL-SQL">[Code]</a></p>
</div>
</div>


# ğŸ”¥ News
- *2025.01*: ğŸ‰ğŸ‰ Two papers are accepted by [NAACL 2025](https://2025.naacl.org/).
- *2025.01*: ğŸ‰ğŸ‰ Three papers are accepted by [ICLR 2025](https://iclr.cc/).
- *2024.10*: ğŸ‰ğŸ‰ Excited to announce the our paper: [MarkLLM: An Open-Source Toolkit for LLM Watermarking](https://arxiv.org/pdf/2405.10051) is accepted by [EMNLP 2024 Demo Track](https://2024.emnlp.org/).
- *2024.09*: ğŸ‰ One paper about Retrieval-Augmented Large Language Models is accepted by [EMNLP 2024](https://2024.emnlp.org/).
- *2024.08*: ğŸ‰ğŸ‰ Excited to announce the our paper: "A Survey of Text Watermarking in the Era of Large Language Models" [Paper](https://arxiv.org/pdf/2312.07913) is accepted by [ACM Computing Surveys](https://dl.acm.org/journal/csur)!
- *2024.08*: Invited as a reviewer for [ICLR 2025](https://iclr.cc/).
- *2024.08*: ğŸ‰ğŸ‰ Excited to announce the updated version of our paper: "A Survey of Text Watermarking in the Era of Large Language Models" [Paper](https://arxiv.org/pdf/2312.07913)!
- *2024.05*: ğŸ‰ğŸ‰ One paper about Large Language Model Alignment is accepted by [ACL 2024](https://2024.aclweb.org/).
- *2024.05*: ğŸ‰ğŸ‰ Two papers about watermark for Large Language Models are accepted by [ACL 2024](https://2024.aclweb.org/).
- *2024.05*: ğŸ‰ğŸ‰ One paper about Document Relation Extraction is accepted by [Findings of ACL 2024](https://2024.aclweb.org/).
- *2024.04*: ğŸ‰ğŸ‰ Our tutorial proposal "Preventing and Detecting Misinformation Generated by Large Language Models" is accepted by SIGIR 2024. [SIGIR 2024](https://sigir-2024.github.io/).
- *2024.04*: Invited as a reviewer for [ACMMM 2024](https://2024.acmmm.org/).
- *2024.04*: Invited as a reviewer for [ACL ARR April](https://openreview.net/group?id=aclweb.org/ACL/ARR/2024/April).
- *2024.02*: Invited as a reviewer for [ACL ARR February](https://openreview.net/group?id=aclweb.org/ACL/ARR/2024/February).
- *2024.01*: ğŸ‰ğŸ‰ Two papers about watermark for Large Language Models are accepted by [ICLR 2024](https://iclr.cc/).





<!-- # ğŸ”¬ Research

* Preventing and Detecting Misinformation Generated by Large Language Models **<span style="color: #ff6666;">(SIGIR 2024 Tutorial)</span>** [[Home]](https://sigir24-llm-misinformation.github.io/) [[Paper]](https://dl.acm.org/doi/10.1145/3626772.3661377)[[Conference Page]](https://sigir-2024.github.io/attend_Tutorials.html#tut5) 1ï¸âƒ£ 

**Watermark for Large Language Models**

*  An Unforgeable Publicly Verifiable Watermark for Large Language Models **<span style="color: #ff6666;">(ICLR 2024)</span>** [[Paper]](https://arxiv.org/pdf/2307.16230.pdf) [[Code]](https://github.com/THU-BPM/unforgeable_watermark) 1ï¸âƒ£
*  A Semantic Invariant Robust Watermark for Large Language Models **<span style="color: #ff6666;">(ICLR 2024)</span>** [[Paper]](https://arxiv.org/pdf/2310.06356.pdf) [[Code]](https://github.com/THU-BPM/Robust_Watermark)1ï¸âƒ£
*  A Survey of Text Watermarking in the Era of Large Language Models **<span style="color: #ff6666;">(ACM Computing Surveys)</span>** [[Paper]](https://arxiv.org/pdf/2312.07913.pdf)[[æœºå™¨ä¹‹å¿ƒ]](https://mp.weixin.qq.com/s/U3ZzGsi3Yihueqr6MGRHfg) [[Twitter]](https://x.com/Aiwei_Liu_99/status/1821673541026099519) [[Home]](https://survey-text-watermark.github.io/)  1ï¸âƒ£
*  Can Watermarked LLMs be Identified by Users via Crafted Prompts? **<span style="color: #ff6666;">(ICLR 2025)</span>** [[Paper]](https://arxiv.org/abs/2410.03168) 1ï¸âƒ£
*  MarkLLM: An Open-Source Toolkit for LLM Watermarking **<span style="color: #ff6666;">(EMNLP 2024 Demo)</span>** [[Paper]](https://arxiv.org/pdf/2405.10051) [[æœºå™¨ä¹‹å¿ƒ]](https://mp.weixin.qq.com/s/lx9ZNeHae4mo1J6_sFubfg) [[Code]](https://github.com/THU-BPM/MarkLLM)ğŸ’¡ 
* An Entropy-based Text Watermarking Detection Method **<span style="color: #ff6666;">(ACL 2024 Main)</span>** [[Paper]](https://arxiv.org/pdf/2403.13485.pdf) [[Code]](https://github.com/luyijian3/EWD)ğŸ’¡ 
* Cross-lingual Consistency for Text Watermark **<span style="color: #ff6666;">(ACL 2024 Main)</span>** [[Paper]](https://arxiv.org/pdf/2402.14007.pdf) [[Code]](https://github.com/zwhe99/X-SIR)ğŸ’¡
* WaterSeeker: Pioneering Efficient Detection of Watermarked Segments in Large Documents **<span style="color: #ff6666;">(NAACL 2025 Findings)</span>** [[Paper]](https://arxiv.org/pdf/2409.05112) ğŸ’¡


**Safety Alignment for Large Language Models**

* Direct Large Language Model Alignment Through Self-Rewarding Contrastive Prompt Distillation **<span style="color: #ff6666;">(ACL 2024 Main)</span>** [[Paper]](https://arxiv.org/pdf/2402.11907.pdf) [[Apple Website]](https://machinelearning.apple.com/research/direct-large-language)1ï¸âƒ£
* TIS-DPO: Token-level Importance Sampling for Direct Preference Optimization With Estimated Weights **<span style="color: #ff6666;">(ICLR 2025)</span>** [[Paper]](https://arxiv.org/pdf/2410.04350v1) 1ï¸âƒ£

**Adversarial Examples for Large Language Models**

* Character-level White-Box Adversarial Attacks against Transformers via Attachable Subwords Substitution **<span style="color: #ff6666;">(EMNLP 2022 Main)</span>** [[Paper]](https://aclanthology.org/2022.emnlp-main.522) [[Code]](https://github.com/THU-BPM/CWBA)1ï¸âƒ£

**Semantic Parsing with Large Language Models**

* Semantic Enhanced Text-to-SQL Parsing via Iteratively Learning Schema Linking Graph **<span style="color: #ff6666;">(SIGKDD 2022)</span>**  [[Paper]](https://dl.acm.org/doi/pdf/10.1145/3534678.3539294) [[Code]](https://github.com/THU-BPM/ISESL-SQL)1ï¸âƒ£ 
* Exploring the Compositional Generalization in Context Dependent Text-to-SQL Parsing **<span style="color: #ff6666;">(ACL 2023 Findings)</span>** [[Paper]](https://aclanthology.org/2023.findings-acl.43.pdf) [[Code]](https://github.com/THU-BPM/CD-Text2SQL-CG)1ï¸âƒ£
* A comprehensive evaluation of ChatGPT's zero-shot Text-to-SQL capability **<span style="color: #ff6666;">(Pre-print)</span>**  [[Paper]](https://arxiv.org/abs/2303.13547) [[Code]](https://github.com/THU-BPM/chatgpt-sql) 1ï¸âƒ£

**Fact Checking with Large Language Models**

* CHEF: A Pilot Chinese Dataset for Evidence-Based Fact-Checking  **<span style="color: #ff6666;">(NAACL 2022)</span>**[[Paper]](https://arxiv.org/abs/2206.11863)  [[Code]](https://github.com/THU-BPM/CHEF)ğŸ’¡ 
  

**Retrieval-Augmented Large Language Models**

* Entropy-Based Decoding for Retrieval-Augmented Large Language Models **<span style="color: #ff6666;">(MINT@NeurIPS2024)</span>**[[Paper]](https://arxiv.org/pdf/2406.17519) ğŸ’¡ 
* Refiner: Restructure Retrieval Content Efficiently to Advance Question-Answering Capabilities **<span style="color: #ff6666;">(EMNLP 2024 Findings)</span>**[[Paper]](https://arxiv.org/pdf/2406.11357) ğŸ’¡  -->

<!-- **Information Extraction**

* GDA: Generative Data Augmentation Techniques for Relation Extraction Tasks [[ACL 2023 Findings]](https://arxiv.org/abs/2305.16663) ğŸ… 
* RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction [[EMNLP 2023]](https://aclanthology.org/2023.emnlp-main.316.pdf) ğŸ’¡ 
* Reading Broadly to Open Your Mind Improving Open Relation Extraction With Search Documents Under Self-Supervisions [[TKDE]](https://ieeexplore.ieee.org/abstract/document/10255305) ğŸ’¡
* Entity-to-Text based Data Augmentation with Semantic Coherence and Entity Preserving for various NER Tasks [[ACL 2023 Findings]](https://aclanthology.org/2023.findings-acl.578.pdf) ğŸ’¡
* Guassian Prior Reinforcement Learning for Nested Named Entity Recognition [[ICASSP 2023]](https://ieeexplore.ieee.org/abstract/document/10097163/) ğŸ’¡ -->


<!-- ---

1ï¸âƒ£: Leading contribution (First Author)
ğŸ’¡: Insightful contribution

---
   -->

# ğŸ“ Contact

- ğŸ“§ **Email**:
  -  liuaw20@mails.tsinghua.edu.cn
  -  liuaiwei20@gmail.com
- ğŸ’¬ **Wechat**:
  - u839134412

# ğŸ“ Services

<div style="font-family: 'Microsoft YaHei';">
<p style="font-size: 18px; font-weight: bold;">Program Committee/Reviewer</p>
<ul style="list-style-type: disc; padding-left: 20px;">
  <li>The International Conference on Learning Representations (ICLR)</li>
  <li>The Annual Meeting of the Association for Computational Linguistics (ACL)</li>
  <li>The Annual Conference on Empirical Methods in Natural Language Processing (EMNLP)</li>
  <li>The Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)</li>
  <li>The Annual Conference of the European Chapter of the Association for Computational Linguistics (EACL)</li>
  <li>The ACM WWW International World Wide Web Conference (WWW)</li>
  <li>The ACM International Conference on Multimedia (MM)</li>
</ul>

<p style="font-size: 18px; font-weight: bold;">Workshop Organization</p>
<ul style="list-style-type: disc; padding-left: 20px;">
  <li>Co-organizer of the <a href="https://aaai2025-llm-misinformation.github.io/">AAAI 2025 Workshop on Preventing and Detecting LLM Generated Misinformation (PDLM)</a></li>
</ul>

<p style="font-size: 18px; font-weight: bold;">Tutorial</p>
<ul style="list-style-type: disc; padding-left: 20px;">
  <li>Lead presenter for "Preventing and Detecting Misinformation Generated by Large Language Models" tutorial at SIGIR 2024</li>
  <li style="list-style-type: none; padding-left: 20px;">Tutorial website: <a href="https://sigir24-llm-misinformation.github.io/">https://sigir24-llm-misinformation.github.io/</a></li>
</ul>
</div>

<p align="center" style="padding-top: 40px;"> <a  href="https://clustrmaps.com/site/1bz29"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=DX15I5ozLq5Q-wR0ekcNB17qazZ99Mm2sOgYD9FXvrM&cl=ffffff&w=300" /></a> </p>

<p align="center" style="padding-top: 100px;"> 
</p>

<style>
.paper-container {
    display: flex;
    gap: 20px;
    margin: 30px 0;
    padding: 15px;
    border-radius: 8px;
    background: #fff;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}

.paper-image {
    flex: 0 0 300px;
    min-width: 0;
}

.paper-image img {
    width: 100%;
    height: auto;
    border-radius: 4px;
    border: 1px solid #eee;
}

.paper-text {
    flex: 1;
    min-width: 0;
}


.paper-title {
  font-family: "Microsoft YaHei",
  font-weight: 2000;
  -webkit-text-stroke: 0.9px black;  /* æ·»åŠ æè¾¹æ•ˆæœä½¿æ–‡å­—çœ‹èµ·æ¥æ›´ç²— */
  font-size: 18px;
  margin: 0 0 8px 0;
  color: #000;
}

.paper-authors {
  font-family: "Microsoft YaHei",
   margin: 2px 0;
    font-size: 14.5px;         /* è°ƒå°ä½œè€…å­—ä½“ */
    color: rgba(0,0,0,0.9);    /* æ›´è‡ªç„¶çš„ç°è‰² */
    font-weight: 400;          /* æ›´ç»†çš„å­—é‡ */
}

.paper-venue {
   font-family: "Microsoft YaHei",
    color: #d83931;
    font-style: italic;
    font-size: 0.95em;
    margin: 3px 0;
}

.paper-links {
  font-family: "Microsoft YaHei",
    font-size: 0.9em;
    margin: 3px 0;
}

.paper-links a {
    margin-right: 10px;
    color: #4A90E2;
    text-decoration: none;
    transition: color 0.2s ease;
}

.paper-links a:hover {
    color: #357ABD;
}

@media (max-width: 768px) {
    .paper-container {
        flex-direction: column;
    }
    
    .paper-image {
        flex: 0 0 auto;
        width: 100%;
    }
}
</style>